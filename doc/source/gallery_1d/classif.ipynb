{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nSelf-contained classification example on the free-spoken digit data recordings\nThis dataset is automatically downloaded and preprocessed from\nhttps://github.com/Jakobovski/free-spoken-digit-dataset.git\n\nDownloading and precomputing scattering coefficients should take about 5 mns.\nRunning the gradient descent takes about 1 mn.\n\nResults:\nTraining accuracy = 99.6%\nTesting accuracy = 95.3%\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom torch.nn import Linear, NLLLoss, LogSoftmax, Sequential\nfrom torch.optim import Adam\nfrom torch.autograd import Variable\nfrom scattering import Scattering1D\nfrom scattering.datasets import fetch_fsdd\nfrom scattering.caching import get_cache_dir\nimport numpy as np\nfrom scipy.io import wavfile\nimport os\nimport json\nimport time\n\n\ndef loadfile(path_file):\n    sr, x = wavfile.read(path_file)\n    x = np.asarray(x, dtype='float')\n    # make it mono\n    if x.ndim > 1:\n        smallest_axis = np.argmin(x.shape)\n        x = x.mean(axis=smallest_axis)\n    x = np.asarray(x, dtype='float')\n    x /= np.max(np.abs(x))\n    return sr, x\n\n\ndef get_fsdd_scattering_coefs(T, J, Q, use_cuda=True, force_compute=False,\n                              cache_name='fsdd', is_train=True,\n                              log_transform=True, log_eps=1e-6,\n                              average_time=True, verbose=True):\n    \"\"\"\n    Downloads, preprocesses and caches the scattering coefficients of the\n    Free Spoken Digit Dataset\n\n    This function is the main entrance function to access the fsdd dataset\n    in an automated fashion.\n\n    Arguments\n    ---------\n    T: int > 0\n        Support of the signals to use (otherwise, signals will be cut or\n        padded to achieve this value)\n    J: int > 0\n        Scale parameter for the scattering transform\n    Q: int > 0\n        Quality factor for the scattering filterbank.\n    use_cuda: boolean, optional\n        Allows to use cuda to speed up operations. Defaults to True\n    force_compute: boolean, optional\n        Whether to force to recompute scattering vectors, even if existing.\n        Defaults to False.\n    cache_name: string, optional\n        Name of the caching directory for this file. Defaults to \"fsdd\"\n    is_train: boolean, optional\n        Whether to provide files related to the training or testing set.\n        Defaults to True\n    log_transform: boolean, optional\n        Whether to take the logarithm of the scattering coefficients, which\n        should be more equally distributed. This removes the zero-order\n        coefficients (averages). Defaults to True.\n    log_eps: float > 0\n        Constant to add to the absolute value of the scattering coefficients\n        before computing the logarithm. Defaults to 1e-6.\n    average_time: boolean, optional\n        Whether to take the average of the scatterings along time, to reduce\n        the dimensionality of the problem. Defaults to True\n    verbose: boolean, optional\n        Whether to display information about what is performed.\n        Defaults to True.\n\n    Returns\n    -------\n    x: torch FloatTensor with 2 axis\n        The input vectors (lines are samples, columns features)\n        The inputs are processed according to the log and averaging operations,\n        if necessary.\n    y: torch LongTensor with 1 axis\n        The output classes (integers from 0 to 9)\n    \"\"\"\n    # Get the aggregated file in the adequate folder\n    x, y = get_agg_scattering_coefs(\n        T, J, Q, use_cuda=use_cuda, force_compute=force_compute,\n        cache_name=cache_name, is_train=is_train, verbose=verbose)\n    if log_transform:\n        x = x[:, 1:, :] # remove order 0\n        x = torch.log(torch.abs(x) + log_eps)\n    if average_time:\n        x = torch.mean(x, dim=-1)\n    else:\n        x = x.view(x.shape(0), -1).contiguous()\n    return x, y\n\n\ndef get_agg_scattering_coefs(T, J, Q, use_cuda=True, force_compute=False,\n                             cache_name='fsdd', is_train=True,\n                             verbose=False):\n    \"\"\"\n    Help function for get_fsdd_dataset.\n    Computes and caches the aggregated dataset for train and test (aggregated\n    along all files, which is possible since the dataset is very small).\n\n    Arguments\n    ---------\n    T: int > 0\n        Support of the signals to use (otherwise, signals will be cut or\n        padded to achieve this value)\n    J: int > 0\n        Scale parameter for the scattering transform\n    Q: int > 0\n        Quality factor for the scattering filterbank.\n    use_cuda: boolean, optional\n        Allows to use cuda to speed up operations. Defaults to True\n    force_compute: boolean, optional\n        Whether to force to recompute scattering vectors, even if existing.\n        Defaults to False.\n    cache_name: string, optional\n        Name of the caching directory for this file. Defaults to \"fsdd\"\n    is_train: boolean, optional\n        Whether to provide files related to the training or testing set.\n        Defaults to True\n    verbose: boolean, optional\n        Whether to display information about what is performed.\n        Defaults to True.\n\n    Returns\n    -------\n    x: torch FloatTensor with 2 axis\n        The input vectors (lines are samples, columns features), un-processed.\n    y: torch LongTensor with 1 axis\n        The output classes (integers from 0 to 9)\n    \"\"\"\n    # Check if the aggregated files for train or test already exist\n    suffix = 'train' if is_train else 'test'\n    path_data = get_cache_dir(os.path.join(cache_name, 'scattering'))\n    input_path = os.path.join(path_data, 'input_' + suffix + '.th')\n    output_path = os.path.join(path_data, 'output_' + suffix + '.th')\n    exists_input = os.path.exists(input_path)\n    exists_output = os.path.exists(output_path)\n    if not(exists_input) or not(exists_output) or force_compute:\n        # get the list of all the scattering coefficients\n        # (they may be recomputed along the way if necessary\n        files = get_detail_scattering_coefs(\n            T, J, Q, use_cuda=use_cuda, force_compute=force_compute,\n            cache_name=cache_name, is_train=is_train, verbose=verbose)\n        if verbose:\n            print('Aggregating individual scattering vectors for', suffix)\n        # Aggregate the files\n        path_dataset = os.path.join(path_data, suffix)\n        s_acc = []\n        y_acc = []\n        for f in files:\n            s = torch.load(os.path.join(path_dataset, f))\n            label = int(f.split('_')[0])\n            y = torch.LongTensor([label])\n            s_acc.append(s.unsqueeze(0))\n            y_acc.append(y.unsqueeze(0))\n        s_acc = torch.cat(s_acc, dim=0)\n        y_acc = torch.squeeze(torch.cat(y_acc, dim=0))\n        # save them\n        torch.save(s_acc, input_path)\n        torch.save(y_acc, output_path)\n    else:\n        s_acc = torch.load(input_path)\n        y_acc = torch.load(output_path)\n    # return the result\n    return s_acc, y_acc\n\n\ndef get_detail_scattering_coefs(T, J, Q, use_cuda=True,\n                                force_compute=False,\n                                cache_name='fsdd', is_train=True,\n                                verbose=False):\n    \"\"\"\n    Get the list of all the class_name_idex.th files for the train/test class\n    If the folder cache_name/scattering/train or test does not exist or\n    if force_compute is True, all the scattering coefficients are recomputed\n    along the way (both for train and test)\n\n    Arguments\n    ---------\n    T: int > 0\n        Support of the signals to use (otherwise, signals will be cut or\n        padded to achieve this value)\n    J: int > 0\n        Scale parameter for the scattering transform\n    Q: int > 0\n        Quality factor for the scattering filterbank.\n    use_cuda: boolean, optional\n        Allows to use cuda to speed up operations. Defaults to True\n    force_compute: boolean, optional\n        Whether to force to recompute scattering vectors, even if existing.\n        Defaults to False.\n    cache_name: string, optional\n        Name of the caching directory for this file. Defaults to \"fsdd\"\n    is_train: boolean, optional\n        Whether to provide files related to the training or testing set.\n        Defaults to True\n    verbose: boolean, optional\n        Whether to display information about what is performed.\n        Defaults to True.\n\n    Returns\n    -------\n    list_train (or list_test): list\n        The list of the files present in the correct caching directory to\n        look after when performing the aggregation. Files are sorted to\n        ensure reproducibility.\n    \"\"\"\n    suffix = 'train' if is_train else 'test'\n    path_dataset = get_cache_dir(\n        name=os.path.join(cache_name, 'scattering', suffix))\n    list_files = sorted(\n        [f for f in os.listdir(path_dataset) if f.endswith('.th')])\n    if len(list_files) > 0 and not(force_compute):\n        return list_files\n    else:\n        # we recompute all scattering coefficients\n        list_train, list_test = compute_scattering_coefs(\n            T, J, Q, use_cuda=use_cuda, cache_name=cache_name, verbose=verbose)\n        if is_train:\n            return list_train\n        else:\n            return list_test\n\n\ndef compute_scattering_coefs(T, J, Q, use_cuda=True, cache_name='fsdd',\n                             verbose=False):\n    \"\"\"\n    Get the list of individual computed scattering coefficients, both for train\n    and test.\n    If not existing, computes and caches them.\n\n    Arguments\n    ---------\n    T: int > 0\n        Support of the signals to use (otherwise, signals will be cut or\n        padded to achieve this value)\n    J: int > 0\n        Scale parameter for the scattering transform\n    Q: int > 0\n        Quality factor for the scattering filterbank.\n    use_cuda: boolean, optional\n        Allows to use cuda to speed up operations. Defaults to True\n    cache_name: string, optional\n        Name of the caching directory for this file. Defaults to \"fsdd\"\n    verbose: boolean, optional\n        Whether to display information about what is performed.\n        Defaults to True.\n\n    Returns\n    -------\n    list_train, list_test:\n        The list of the files present in the correct caching directory to\n        look after when performing the aggregation. Files are sorted to\n        ensure reproducibility.\n    \"\"\"\n    # 1) Download the dataset (if not existing)\n    info_data = fetch_fsdd(verbose=verbose)\n    files = sorted(info_data['files'])\n    path_data = info_data['path_dataset']\n    # 2) Preprocess with the scattering\n    if verbose:\n        print(\"Computing scattering coefficients\")\n    scattering = Scattering1D(T, J, Q)\n    if use_cuda:\n        scattering = scattering.cuda()\n    # build the caching directory\n    path_temp = {\n        suffix: get_cache_dir(\n            name=os.path.join(cache_name, 'scattering', suffix))\n        for suffix in ['train', 'test']}\n\n    n = len(files)\n    t0 = time.time()\n    for count, f in enumerate(files):\n        t1 = time.time()\n        print(\"{}/{} - Time elapsed: {:0.2f}s\".format(count, n, t1 - t0),\n              end=\"\\r\")\n        # load the file\n        rate, x = loadfile(os.path.join(path_data, f))\n        if x.size <= T:\n            # pad it with zeros:\n            missing = T - x.size\n            x_padded = np.zeros(T, dtype='float32')\n            left_pad = (T - len(x)) // 2\n            x_padded[left_pad:left_pad + len(x)] = x\n            x = Variable(torch.from_numpy(x_padded[np.newaxis, np.newaxis]))\n            if use_cuda:\n                x = x.cuda()\n            # compute the scattering\n            s = scattering.forward(x).data[0]\n            if use_cuda:\n                x = x.cpu()\n                s = s.cpu()\n        else:\n            s_acc = []\n            # split it\n            num_chunks = -(-x.size // T)  # negative integer divison for ceil\n            for i in range(num_chunks):\n                if i == num_chunks - 1:\n                    data = torch.from_numpy(x[-T:]).float()\n                else:\n                    data = torch.from_numpy(x[i * T: (i + 1) * T]).float()\n                data = Variable(data.unsqueeze(0).unsqueeze(0))\n                if use_cuda:\n                    data = data.cuda()\n                s = scattering.forward(data).data\n                if use_cuda:\n                    data = data.cpu()\n                    s = s.cpu()\n                s_acc.append(s)\n            # average them\n            s_acc = torch.cat(s_acc, dim=0)\n            s = s_acc.mean(dim=0)\n\n        # store it in the adequate folder\n        info = f.split('_')\n        name = f.split('.')[0]\n        is_train = int(info[2].split('.')[0]) >= 5\n        suffix = 'train' if is_train else 'test'\n        torch.save(s, os.path.join(path_temp[suffix], name + '.th'))\n    # list all the files in train and test\n    files_train = sorted(\n        [f for f in os.listdir(path_temp['train']) if f.endswith('.th')])\n    files_test = sorted(\n        [f for f in os.listdir(path_temp['test']) if f.endswith('.th')])\n    return files_train, files_test\n\n\ndef compute_loss_and_accuracy(net, criterion, x, y):\n    \"\"\"\n    Computes the loss and accuracy of the model net with the given\n    criterion for the dataset (x, y)\n\n    Arguments\n    ---------\n    net: torch Module\n    criterion: torch loss function\n    x: input Tensor (variable)\n    y: expected output tensor (variable)\n\n    Returns\n    -------\n    avg_loss: float\n        average loss across the dataset\n    accuracy: float\n        average accuracy across the dataset, that is:\n        average number of samples for which the network assigns the\n        maximal probability for the correct class.\n    \"\"\"\n    all_losses = []\n    all_successes = []\n    for i in range(x.shape[0]):\n        resp = net.forward(x[i].unsqueeze(0))\n        loss = criterion(resp, y[i:i+1])\n        all_losses.append(loss.data.cpu()[0])\n        # find the argmax of resp\n        sub_resp = torch.squeeze(resp.data.cpu()).numpy()\n        success = np.argmax(sub_resp) == y[i].data[0]\n        all_successes.append(success)\n    avg_loss = np.array(all_losses).mean()\n    accuracy = np.array(all_successes).mean()\n    return avg_loss, accuracy\n\n\nif __name__ == '__main__':\n    T = 2**13  # support size we use\n    J = 8  # averaging scale of the scattering\n    Q = 12  # quality factor for the wavelet transform\n    log_transform = True  # use the log of the scattering\n    log_eps = 1e-6 # constant to prevent small arguments of the log\n    average_time = True  # average scattering along time\n    batch_size = 32  # batch_size\n    num_epochs = 50  # number of epochs\n    lr = 1e-4  # learning rate (ADAM)\n    random_state = 42  # random seed for reproducibility\n    use_cuda = torch.cuda.is_available()  # whether to use cuda\n    verbose = True  # print intermediate steps\n    cache_name = 'fsdd'  # name of the cache folder\n    num_classes = 10  # number of classes for the problem\n    force_compute = False  # forces to recompute scattering features\n    # set the seed\n    torch.manual_seed(random_state)  # set the seed\n    # GETTING TRAINING FEATURES\n    X_tr, y_tr = get_fsdd_scattering_coefs(\n        T, J, Q, use_cuda=use_cuda, cache_name=cache_name, is_train=True,\n        log_transform=log_transform, log_eps=log_eps,\n        average_time=average_time, force_compute=force_compute)\n    nsamples = X_tr.shape[0]\n    nbatches = nsamples // batch_size\n    # whiten the dataset\n    mu_tr = X_tr.mean(dim=0)\n    std_tr = X_tr.std(dim=0)\n    X_tr = (X_tr - mu_tr) / std_tr\n\n    # move to GPU if necessary\n    if use_cuda:\n        X_tr = X_tr.cuda()\n        y_tr = y_tr.cuda()\n    # embed them in variables\n    X_tr = Variable(X_tr, requires_grad=False)\n    y_tr = Variable(y_tr, requires_grad=False)\n\n    # DEFINE THE MODEL\n    model = Sequential(Linear(X_tr.shape[-1], num_classes), LogSoftmax())\n    optimizer = Adam(model.parameters())\n    criterion = NLLLoss()\n    if use_cuda:\n        model = model.cuda()\n        criterion = criterion.cuda()\n\n    # perform the gradient descent\n    for e in range(num_epochs):\n        # permutation of the dataset\n        perm = torch.randperm(nsamples)\n        if use_cuda:\n            perm = perm.cuda()\n        for i in range(nbatches):\n            model.zero_grad()\n            resp = model.forward(\n                X_tr[perm[i * batch_size: (i + 1) * batch_size]])\n            loss = criterion(\n                resp, y_tr[perm[i * batch_size: (i + 1) * batch_size]])\n            loss.backward()\n            optimizer.step()\n        # compute the loss and the accuracy\n        avg_loss, accu = compute_loss_and_accuracy(model, criterion,\n                                                   X_tr, y_tr)\n        print('Epoch {}, average loss = {:1.3f}, accuracy = {:1.3f}'.format(\n            e, avg_loss, accu))\n\n    # Load testing features\n    X_te, y_te = get_fsdd_scattering_coefs(\n        T, J, Q, use_cuda=use_cuda, cache_name=cache_name, is_train=False,\n        log_transform=log_transform, average_time=average_time,\n        force_compute=force_compute)\n    X_te = (X_te - mu_tr) / std_tr\n    if use_cuda:\n        X_te = X_te.cuda()\n        y_te = y_te.cuda()\n    X_te = Variable(X_te, requires_grad=False)\n    y_te = Variable(torch.squeeze(y_te), requires_grad=False)\n\n    avg_loss, accu = compute_loss_and_accuracy(model, criterion, X_te, y_te)\n    print('TEST, average loss = {:1.3f}, accuracy = {:1.3f}'.format(\n          avg_loss, accu))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}