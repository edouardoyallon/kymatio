.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_gallery_1d_compute_speed.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_gallery_1d_compute_speed.py:


Benchmark the speed of the 1D scattering transform
==================================================
We compute scattering transforms for signals of length `T = 2**16`, with scale
`J = 10` and `Q = 8` wavelets per octave. The signals are stacked into batches
of size `batch_size = 64` and the transform is computed `10` times to get an
average running time.



.. code-block:: python


    import torch
    import time
    import scattering.scattering1d.backend as backend
    from scattering import Scattering1D


Parameters for the benchmark
----------------------------



.. code-block:: python


    T = 2**16
    Q = 8
    J = 10

    batch_size = 64

    times = 10


Set up the scattering object and the test data
----------------------------------------------



.. code-block:: python


    scattering = Scattering1D(T, J, Q)

    x_data = torch.randn(batch_size, 1, T, dtype=torch.float32)


Benchmark the PyTorch backend
-----------------------------
If we're using the this backend, compute scattering transforms both on CPU
and GPU so that we can compare performance.



.. code-block:: python


    if backend.NAME == 'torch':
        devices = ['cpu']
        if torch.cuda.is_available():
            devices.append('gpu')

        for device in devices:
            fmt_str = '==> Testing Float32 with Torch backend, on {}, forward'
            print(fmt_str.format(device.upper()))

            if device == 'gpu':
                scattering.cuda()
                x_data = x_data.cuda()
            else:
                scattering.cpu()
                x_data = x_data.cpu()

            if device == 'gpu':
                torch.cuda.synchronize()

            t_start = time.time()
            for _ in range(times):
                scattering(x_data)

            if device == 'gpu':
                torch.cuda.synchronize()

            t_elapsed = time.time() - t_start

            fmt_str = 'Elapsed time: {:2f} [s / {:d} evals], avg: {:.2f} (s/batch)'
            print(fmt_str.format(t_elapsed, times, t_elapsed/times))

**Total running time of the script:** ( 0 minutes  0.000 seconds)


.. _sphx_glr_download_gallery_1d_compute_speed.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: compute_speed.py <compute_speed.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: compute_speed.ipynb <compute_speed.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
